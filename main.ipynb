{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtqmMBBFM5VB",
        "tags": [
          "remove_cell"
        ]
      },
      "source": [
        "# Page Rank and Recommendation Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxkmPDaWrYRM"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTVP9OLGrYRN",
        "tags": [
          "remove_output"
        ]
      },
      "outputs": [],
      "source": [
        "!pip install scikit-network\n",
        "from sknetwork.utils import get_neighbors; \n",
        "import sknetwork\n",
        "from sknetwork.ranking import PageRank\n",
        "from collections import defaultdict\n",
        "import numpy as np; import pandas as pd\n",
        "\n",
        "!pip install scikit-surprise scipy==1.4.1\n",
        "from surprise import Dataset , Reader, prediction_algorithms\n",
        "from surprise.model_selection import KFold, cross_validate, RandomizedSearchCV, GridSearchCV\n",
        "import numpy as np; import pandas as pd \n",
        "import multiprocessing\n",
        "from os import replace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyULCTYnrYRO"
      },
      "source": [
        "## Page Rank\n",
        "Using the provided dataset we will run various PageRank algorithms.\n",
        "The dataset is an unweighted and undirected graph, where nodes represent characters from the \"Harry Potter\" books and an edge connects two characters in the graph if their names appeared at least one time within 14 words of one another in at least one of the books."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZarHAE1mrYRO"
      },
      "source": [
        "### Downloading the dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zfy4RvLDrYRP",
        "tags": [
          "remove_cell"
        ]
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown 11Fa9zqDPgDthm3B84My1flWN6r-ffpY0 # download harry_potter_graph1.csv\n",
        "\n",
        "df = pd.read_csv(r'/content/harry_potter_graph1.csv') # load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExTNrAB0rYRR"
      },
      "source": [
        "### Adjacency Matrix\n",
        "Creating the adjacency matrix for the graph, assigning to each character a node identifier equal to the index that the character name has in ascending alphabetical order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqb_1UZwrYRS"
      },
      "outputs": [],
      "source": [
        "records = df.to_records(index=False)\n",
        "result = list(records)\n",
        "\n",
        "Adj_matrix = sknetwork.data.from_edge_list(result,directed = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDMyeP1hrYRS"
      },
      "source": [
        "### Standard PageRank\n",
        "Computing the PageRank vector for the obtained graph using a damping factor of 0.8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF4p5lEHrYRT"
      },
      "outputs": [],
      "source": [
        "damping_factor = 0.8 # Set the parameters for the PageRank computation\n",
        "\n",
        "# PageRank\n",
        "pagerank = PageRank(damping_factor=damping_factor, solver=\"piteration\", n_iter=1000, tol=10**-6)\n",
        "\n",
        "# Compute Page-Rank on the entire WIKIPEDIA graph\n",
        "pagerank_vector = pagerank.fit_transform(Adj_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1ad6G92-mzf",
        "tags": [
          "remove_cell"
        ]
      },
      "source": [
        "Name and the PageRank score of the top-10 characters according to the PageRank score of their associated nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uyg1PRkl-mzx",
        "outputId": "4ec92119-3fef-426d-fb55-c2c2be92228f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Harry Potter', 0.09148639794124665)\n",
            "('Ronald Weasley', 0.0377128469364456)\n",
            "('Rubeus Hagrid', 0.034322855633921345)\n",
            "('Hermione Granger', 0.029204887471029867)\n",
            "('Albus Dumbledore', 0.026936454399403835)\n",
            "('Draco Malfoy', 0.022058455723732086)\n",
            "('Neville Longbottom', 0.0215985445672487)\n",
            "('Severus Snape', 0.02128201436448089)\n",
            "('Dudley Dursley', 0.018598199943271058)\n",
            "('Vernon Dursley', 0.015355015870565602)\n"
          ]
        }
      ],
      "source": [
        "top10_characters = pd.Series(pagerank_vector).sort_values(ascending = False).index[:10]\n",
        "result = zip(characters.iloc[top10_characters],pd.Series(pagerank_vector).sort_values(ascending = False))\n",
        "\n",
        "for i in list(result):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcxLpyBq-ygQ"
      },
      "source": [
        "### Topic-specific PageRank\n",
        "Computing the Topic-specific PageRank vector for the obtained graph using a damping factor of 0.9, by considering as topic the Weasley family: a character belongs to the topic if its name contains the string `Weasley`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cj7Gn9O-ygg"
      },
      "outputs": [],
      "source": [
        "damping_factor = 0.9\n",
        "\n",
        "# define the topic as probability distribution over all pages.\n",
        "topic_as_map__page_id__landing_probability = {}\n",
        "topic = set(np.where(characters.str.contains('Weasley'))[0])\n",
        "\n",
        "pagerank = PageRank(damping_factor=damping_factor, solver=\"piteration\", n_iter=1000, tol=10 ** -6)\n",
        "num_pages_belonging_to_the_topic = len(topic)\n",
        "\n",
        "for c_page_id_belonging_to_the_topic in topic:\n",
        "    topic_as_map__page_id__landing_probability[c_page_id_belonging_to_the_topic] = 1. / num_pages_belonging_to_the_topic\n",
        "\n",
        "# Compute Page-Rank on the entire WIKIPEDIA graph\n",
        "pagerank_vector = pagerank.fit_transform(Adj_matrix, seeds=topic_as_map__page_id__landing_probability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW5fzpmE-ygj",
        "tags": [
          "remove_cell"
        ]
      },
      "source": [
        "Name and PageRank score of the top-20 characters according to the Topic-specific PageRank score of their associated nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcH9NXMY-ygj",
        "outputId": "396c57b3-a617-4f80-9806-833815bbc846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Harry Potter', 0.08638847973240897)\n",
            "('Ronald Weasley', 0.07563217455276044)\n",
            "('Fred Weasley', 0.0488022781561461)\n",
            "('Percy Weasley', 0.04819506816368508)\n",
            "('George Weasley', 0.044857815227002336)\n",
            "('Rubeus Hagrid', 0.04166899845361425)\n",
            "('Hermione Granger', 0.040928540047301405)\n",
            "('Severus Snape', 0.03177222185978592)\n",
            "('Albus Dumbledore', 0.030666633968766975)\n",
            "('Neville Longbottom', 0.02855735065951652)\n",
            "('Draco Malfoy', 0.02811852222369894)\n",
            "('Argus Filch', 0.018016386207319476)\n",
            "('Quirinus Quirrell', 0.017652339367384282)\n",
            "('Filius Flitwick', 0.016014378892504025)\n",
            "('Rolanda Hooch', 0.015328808733499977)\n",
            "('Oliver Wood', 0.013814761365697727)\n",
            "('Poppy Pomfrey', 0.013283981011776176)\n",
            "('Peeves', 0.013125141816660331)\n",
            "('Vernon Dursley', 0.01243625668149427)\n",
            "('Seamus Finnigan', 0.012067612125960891)\n"
          ]
        }
      ],
      "source": [
        "top20_topic_specific_characters = pd.Series(pagerank_vector).sort_values(ascending = False).index[:20]\n",
        "result = zip(characters.iloc[top20_topic_specific_characters],pd.Series(pagerank_vector).sort_values(ascending = False))\n",
        "\n",
        "for i in list(result): print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWVFUOX1-y4k"
      },
      "source": [
        "### Personalized PageRank\n",
        "Computing the Personalized PageRank vector for the obtained graph using a damping factor of 0.1 for each of the *Hogwarts professors*: Albus Dumbledore, Filius Flitwick, Firenze, Minerva McGonagall, Pomona Sprout, Quirinus Quirrell, Rolanda Hooch, Severus Snape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTMKagGW-y4l"
      },
      "outputs": [],
      "source": [
        "damping_factor = 0.1\n",
        "\n",
        "prof_dict = defaultdict()\n",
        "prof = {'Albus Dumbledore', 'Filius Flitwick', 'Firenze', 'Minerva McGonagall', 'Pomona Sprout', 'Quirinus Quirrell', 'Rolanda Hooch', 'Severus Snape'}\n",
        "\n",
        "for p in prof:\n",
        " \n",
        "  pagerank = PageRank(damping_factor=damping_factor, solver=\"piteration\", n_iter=1000, tol=10 ** -6)\n",
        "  topic = np.where(characters.str.contains(p))[0][0]\n",
        "  \n",
        "  # define the topic as probability distribution over all pages.\n",
        "  map__page_id__landing_probability = {}\n",
        "  map__page_id__landing_probability[topic] = 1.\n",
        "\n",
        "  # Compute Page-Rank on the entire WIKIPEDIA graph\n",
        "  prof_dict[p] = pd.Series(pagerank.fit_transform(Adj_matrix, seeds=map__page_id__landing_probability))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh1B87tu-y4m",
        "tags": [
          "remove_cell"
        ]
      },
      "source": [
        "For each of the *Hogwarts professors*, Name and PageRank score of the top-3 characters according to the Personalized PageRank score of their associated nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6tPqQ2F-y4m",
        "outputId": "a691ca7c-a9f7-4bff-f097-e49a97ad91ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Rolanda Hooch : \n",
            "\n",
            "('Rolanda Hooch', 0.9007978604549658)\n",
            "('Harry Potter', 0.009643772268233819)\n",
            "('Marcus Flint', 0.009447364028106456)\n",
            "\n",
            " Filius Flitwick : \n",
            "\n",
            "('Filius Flitwick', 0.9012523255582493)\n",
            "('Harry Potter', 0.007522154089004595)\n",
            "('Rubeus Hagrid', 0.007390985801524833)\n",
            "\n",
            " Minerva McGonagall : \n",
            "\n",
            "('Minerva McGonagall', 0.9001087192041455)\n",
            "('Harry Potter', 0.09023765774140742)\n",
            "('Ronald Weasley', 0.00017638475484577383)\n",
            "\n",
            " Pomona Sprout : \n",
            "\n",
            "('Pomona Sprout', 0.9004920355342453)\n",
            "('Harry Potter', 0.023081648236240523)\n",
            "('Rubeus Hagrid', 0.023003309933920555)\n",
            "\n",
            " Firenze : \n",
            "\n",
            "('Firenze', 0.9007126647679351)\n",
            "('Harry Potter', 0.01879735971184817)\n",
            "('Rubeus Hagrid', 0.018728925094841017)\n",
            "\n",
            " Severus Snape : \n",
            "\n",
            "('Severus Snape', 0.900914492640715)\n",
            "('Harry Potter', 0.0047108258088581385)\n",
            "('Ronald Weasley', 0.004468580330940453)\n",
            "\n",
            " Albus Dumbledore : \n",
            "\n",
            "('Albus Dumbledore', 0.9016422923261983)\n",
            "('Harry Potter', 0.004357769145351472)\n",
            "('Rubeus Hagrid', 0.0040012249945617934)\n",
            "\n",
            " Quirinus Quirrell : \n",
            "\n",
            "('Quirinus Quirrell', 0.9013688897003601)\n",
            "('Harry Potter', 0.006839822058093201)\n",
            "('Rubeus Hagrid', 0.006705158193645517)\n"
          ]
        }
      ],
      "source": [
        "for key in prof_dict:\n",
        "  print('\\n', key, ': \\n')\n",
        "  top3_personalized_characters = prof_dict[key].sort_values(ascending = False).index[:3]\n",
        "  result = zip(characters.iloc[top3_personalized_characters], prof_dict[key].sort_values(ascending = False))\n",
        "\n",
        "  for i in list(result):\n",
        "      print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTo5DrCICbkA"
      },
      "source": [
        "### Topic-specific PageRank in an online context\n",
        "Computing Topic-specific PageRank for the obtained graph using a damping factor of 0.1 considering an **online** context.\n",
        "\n",
        "The Topic is the Hogwarts professors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d4q8tO-CbkG"
      },
      "outputs": [],
      "source": [
        "aggregated_map__page_id__PersonalizedPageRank_score = {}\n",
        "n = len(prof_dict)\n",
        "\n",
        "for key in prof_dict.keys():\n",
        "\n",
        "    for page_id, PersonalizedPageRank_score in prof_dict[key].items():\n",
        "\n",
        "        if page_id not in aggregated_map__page_id__PersonalizedPageRank_score:\n",
        "            aggregated_map__page_id__PersonalizedPageRank_score[page_id] = 0.\n",
        "\n",
        "        aggregated_map__page_id__PersonalizedPageRank_score[page_id] += PersonalizedPageRank_score / n\n",
        "\n",
        "aggregated_pr = list(aggregated_map__page_id__PersonalizedPageRank_score.items())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O_C-Ig4CbkH",
        "tags": [
          "remove_cell"
        ]
      },
      "source": [
        "Name and the PageRank score of the top-10 characters according to the Topic-specific PageRank score of their associated nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzJNQ7RqCbkI",
        "outputId": "402305ea-c1a4-4cb9-fa33-415b13a0e5d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Albus Dumbledore', 0.11642865404241108)\n",
            "('Filius Flitwick', 0.11606050273075146)\n",
            "('Severus Snape', 0.11493678629257519)\n",
            "('Quirinus Quirrell', 0.11373421500975188)\n",
            "('Pomona Sprout', 0.11348607396745644)\n",
            "('Firenze', 0.11305802182590392)\n",
            "('Rolanda Hooch', 0.11267541641280335)\n",
            "('Minerva McGonagall', 0.11252487770806523)\n",
            "('Harry Potter', 0.020648876132379666)\n",
            "('Rubeus Hagrid', 0.008061659078349088)\n"
          ]
        }
      ],
      "source": [
        "idx = [] ; pr = []\n",
        "for el in sorted(aggregated_pr, key=lambda tup: tup[1])[-10:][::-1]:\n",
        "  idx.append(el[0]); pr.append(el[1])\n",
        "\n",
        "result = zip(characters.iloc[idx], pr)\n",
        "\n",
        "for i in list(result): print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUikJP59ebgQ"
      },
      "source": [
        "## Recommendation Systems\n",
        "In this part we'll improve the performance of various recommendation-systems by using non-trivial algorithms and also by performing the tuning of the hyper-parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz5AtR_6ge6h"
      },
      "source": [
        "### Downloading the dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoz3kpEZge6q",
        "tags": [
          "remove_cell"
        ]
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "!gdown 1MKE_PY0v30CP_rs3sNzwkmo6QvKAVn_J \n",
        "\n",
        "file_path = '/content/ratings_hw2.csv'\n",
        "reader = Reader(line_format='user item rating', sep=',', rating_scale=[3, 5], skip_lines=1)\n",
        "\n",
        "data = Dataset.load_from_file(file_path, reader=reader) # surprise data structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72kpxJnjZv40"
      },
      "source": [
        "### Recommendation algorithms\n",
        "Defining **all** the algorithms we are going to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUTQOaEYZ0LY"
      },
      "outputs": [],
      "source": [
        "#YOUR CODE STARTS HERE#\n",
        "NP = prediction_algorithms.random_pred.NormalPredictor()\n",
        "BO = prediction_algorithms.baseline_only.BaselineOnly()\n",
        "KNNB = prediction_algorithms.knns.KNNBasic()\n",
        "KNNM = prediction_algorithms.knns.KNNWithMeans()\n",
        "KNNZ = prediction_algorithms.knns.KNNWithZScore()\n",
        "KNNBaseline = prediction_algorithms.knns.KNNBaseline()\n",
        "SVD = prediction_algorithms.matrix_factorization.SVD()\n",
        "SVD_pp = prediction_algorithms.matrix_factorization.SVDpp()\n",
        "NMF = prediction_algorithms.matrix_factorization.NMF()\n",
        "SlopeOne = prediction_algorithms.slope_one.SlopeOne()\n",
        "CoClust = prediction_algorithms.co_clustering.CoClustering()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBoF_e5reRQR"
      },
      "source": [
        "### Parameter configuration\n",
        "Defining the parameter configurations for each selected algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyxdQmr6e-sZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "baseline_predictor_options = {   \n",
        "  'method': \"sgd\",  # Optimization method to use.\n",
        "  'learning_rate': 0.005,  # Learning rate parameter for the SGD optimization method.\n",
        "  'n_epochs': 50,  # The number of iteration for the SGD optimization method.\n",
        "  'reg': 0.02,  # The regularization parameter of the cost function that is optimized: a.k.a. LAMBDA.\n",
        "}\n",
        "\n",
        "BO = prediction_algorithms.baseline_only.BaselineOnly(bsl_options=baseline_predictor_options, verbose=True)\n",
        "\n",
        "KNNB = prediction_algorithms.knns.KNNBasic(k=40, min_k=1, verbose=True)\n",
        "\n",
        "KNNM = prediction_algorithms.knns.KNNWithMeans(k=40, min_k=1, verbose=True)\n",
        "\n",
        "KNNZ = prediction_algorithms.knns.KNNWithZScore(k=40, min_k=1, verbose=True)\n",
        "\n",
        "KNNBaseline = prediction_algorithms.knns.KNNBaseline(k=40, min_k=1, verbose=True)\n",
        "\n",
        "SVD = prediction_algorithms.matrix_factorization.SVD(n_factors=100,biased=True,n_epochs=20,lr_all=0.005,reg_all=0.02,verbose=True)\n",
        "\n",
        "SVD_pp = prediction_algorithms.matrix_factorization.SVDpp(n_factors=20,n_epochs=20,lr_all=0.007,reg_all=0.02,verbose=True)\n",
        "\n",
        "NMF = prediction_algorithms.matrix_factorization.NMF()\n",
        "\n",
        "SlopeOne = prediction_algorithms.slope_one.SlopeOne()\n",
        "\n",
        "CoClust = prediction_algorithms.co_clustering.CoClustering()\n",
        "\n",
        "alg=[NP,BO,KNNB,KNNM,KNNZ,KNNBaseline,SVD,SVD_pp,NMF,SlopeOne,CoClust]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_nMGmT3u_WD",
        "tags": [
          "remove_cell"
        ]
      },
      "source": [
        "### K-fold cross validation\n",
        "\n",
        "Initializing a `scikit-surprise` `KFold` object with 5-folds. Random_state set to **42**.\n",
        "\n",
        "\n",
        "Running a **5-Folds**-cross-validation for all the selected algorithms, using the parameters configuration selected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83ZbCXhmu_yC",
        "outputId": "560f8627-1da5-4d2c-f9c7-523b46978eac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating MAE of algorithm NormalPredictor on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.6107  0.6151  0.6106  0.6146  0.6142  0.6131  0.0020  \n",
            "Fit time          0.12    0.12    0.12    0.12    0.06    0.11    0.02    \n",
            "Test time         0.25    0.25    0.24    0.25    0.14    0.23    0.04    \n",
            "\n",
            "\n",
            "Evaluating MAE of algorithm BaselineOnly on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.3732  0.3736  0.3693  0.3698  0.3722  0.3716  0.0018  \n",
            "Fit time          0.70    0.75    1.12    0.71    0.37    0.73    0.24    \n",
            "Test time         0.17    0.51    0.18    0.16    0.10    0.22    0.15    \n",
            "\n",
            "\n",
            "Evaluating MAE of algorithm KNNBasic on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.3898  0.3921  0.3845  0.3872  0.3888  0.3885  0.0025  \n",
            "Fit time          0.43    0.61    0.66    0.64    0.44    0.56    0.10    \n",
            "Test time         5.36    6.15    5.90    4.52    2.73    4.93    1.23    \n",
            "\n",
            "\n",
            "Evaluating MAE of algorithm KNNWithMeans on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.3771  0.3778  0.3732  0.3736  0.3766  0.3757  0.0019  \n",
            "Fit time          0.43    0.62    0.69    0.59    0.45    0.56    0.10    \n",
            "Test time         5.46    6.36    6.27    5.19    3.14    5.28    1.16    \n",
            "\n",
            "\n",
            "Evaluating MAE of algorithm KNNWithZScore on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.3755  0.3757  0.3723  0.3721  0.3747  0.3741  0.0016  \n",
            "Fit time          0.58    0.92    0.93    0.90    0.51    0.77    0.18    \n",
            "Test time         6.02    7.09    6.91    5.75    3.64    5.88    1.23    \n",
            "\n",
            "\n",
            "Evaluating MAE of algorithm KNNBaseline on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.3688  0.3699  0.3647  0.3653  0.3686  0.3674  0.0021  \n",
            "Fit time          0.46    0.80    0.81    0.85    0.48    0.68    0.17    \n",
            "Test time         6.19    7.46    7.00    5.96    3.77    6.08    1.27    \n",
            "\n",
            "\n",
            "Evaluating MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.3774  0.3775  0.3732  0.3743  0.3768  0.3759  0.0018  \n",
            "Fit time          9.14    11.01   10.84   9.27    5.64    9.18    1.93    \n",
            "Test time         0.24    0.30    0.23    0.23    0.15    0.23    0.05    \n",
            "\n",
            "\n",
            "Evaluating MAE of algorithm SVDpp on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.3733  0.3723  0.3675  0.3686  0.3714  0.3706  0.0022  \n",
            "Fit time          302.00  302.91  302.48  303.69  149.25  272.07  61.41   \n",
            "Test time         5.06    6.54    5.17    4.89    2.78    4.89    1.20    \n",
            "\n",
            "\n",
            "Evaluating MAE of algorithm NMF on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.4098  0.4076  0.4029  0.4052  0.4057  0.4063  0.0023  \n",
            "Fit time          9.01    10.77   10.64   9.01    5.44    8.98    1.92    \n",
            "Test time         0.20    0.21    0.20    0.21    0.13    0.19    0.03    \n",
            "\n",
            "\n",
            "Evaluating MAE of algorithm SlopeOne on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.3748  0.3756  0.3714  0.3709  0.3738  0.3733  0.0019  \n",
            "Fit time          1.08    1.65    1.64    1.52    1.05    1.39    0.27    \n",
            "Test time         4.42    4.95    4.72    3.80    2.11    4.00    1.02    \n",
            "\n",
            "\n",
            "Evaluating MAE of algorithm CoClustering on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.4456  0.4400  0.4358  0.4405  0.4423  0.4409  0.0032  \n",
            "Fit time          1.42    1.38    1.40    1.41    0.80    1.28    0.24    \n",
            "Test time         0.18    0.20    0.18    0.18    0.12    0.17    0.03    \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "kf = KFold(n_splits=5, random_state=42)\n",
        "\n",
        "mean_score=[]\n",
        "for method in alg:\n",
        "    cv = cross_validate(method, data, measures=['MAE'], cv=kf, verbose=True,n_jobs= -1)\n",
        "    print('\\n')\n",
        "    mean_score.append((sum(cv['test_mae'])/5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBnOS1InfF4T"
      },
      "source": [
        "### Rank\n",
        "Ranking all recommendation algorithms according to the mean of the Mean Absolute Error metric value: from the best to the worst algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "tz3cg5gVZ-C2",
        "outputId": "3bdf6a6b-5b62-4beb-b2b1-aabb41884822"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-03267396-f909-40c9-b65d-138084fcf2c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNNBaseline</td>\n",
              "      <td>0.367445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SVD++</td>\n",
              "      <td>0.370623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BaselineOnly</td>\n",
              "      <td>0.371619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SlopeOne</td>\n",
              "      <td>0.373288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KNNWithZScore</td>\n",
              "      <td>0.374053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KNNWithMeans</td>\n",
              "      <td>0.375658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SVD</td>\n",
              "      <td>0.375860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KNNBasic</td>\n",
              "      <td>0.388473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NMF</td>\n",
              "      <td>0.406271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CoClust</td>\n",
              "      <td>0.440851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NormalPredictor</td>\n",
              "      <td>0.613054</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03267396-f909-40c9-b65d-138084fcf2c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-03267396-f909-40c9-b65d-138084fcf2c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-03267396-f909-40c9-b65d-138084fcf2c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  0         1\n",
              "5       KNNBaseline  0.367445\n",
              "7             SVD++  0.370623\n",
              "1      BaselineOnly  0.371619\n",
              "9          SlopeOne  0.373288\n",
              "4     KNNWithZScore  0.374053\n",
              "3      KNNWithMeans  0.375658\n",
              "6               SVD  0.375860\n",
              "2          KNNBasic  0.388473\n",
              "8               NMF  0.406271\n",
              "10          CoClust  0.440851\n",
              "0   NormalPredictor  0.613054"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "names = (\"NormalPredictor\",\"BaselineOnly\",\"KNNBasic\",\"KNNWithMeans\",\"KNNWithZScore\",\"KNNBaseline\",\"SVD\",\"SVD++\",\"NMF\",\"SlopeOne\",\"CoClust\")\n",
        "\n",
        "result = list(zip(names, mean_score))\n",
        "\n",
        "data = pd.DataFrame(result)\n",
        "\n",
        "data.sort_values(1, ascending=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "l4lz07FFZj9C",
        "UDqenDoaZEuy",
        "ElJWkdNXShsb",
        "KCoIbBZcrYRH",
        "IxkmPDaWrYRM",
        "ZarHAE1mrYRO",
        "Lr71odinrYRQ",
        "S3F_8xyFrYRR",
        "ExTNrAB0rYRR",
        "lDMyeP1hrYRS",
        "KisyJ9B9rYRa",
        "9rqpaEKvZupX",
        "hUMQy6fnJ_Wc"
      ],
      "name": "Ghinassi_Savarese_DMT2022HW2_notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit (windows store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "ac65af7bcc05c46018d2168487b380d12ed09a67d990cd7ad2a92d2f0784696d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
